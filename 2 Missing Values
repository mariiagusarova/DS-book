import numpy as np
import pandas as pd

#load dataset
loan = pd.read_csv('../input/lending-club/accepted_2007_to_2018Q4.csv.gz', compression='gzip', low_memory=True)

loan.info(verbose=True)

loans = loan[['loan_amnt', 'term','int_rate', 'sub_grade', 'emp_length',
'home_ownership', 'annual_inc', 'loan_status', 'addr_state', 'dti',
'mths_since_recent_inq', 'revol_util', 'bc_open_to_buy', 'bc_util',
'num_op_rev_tl']]

#check missing values
missing_data = pd.DataFrame({'total_missing': loans.isnull().sum(), '%_missing':
(loans.isnull().sum()/2260701)*100})
missing_data


#This is how we can see rows samples where emp_length values are missing
null_data = loans[loans['emp_length'].isnull()]
null_data



#example code how to populate these missing values
From sklearn.impute import SimpleImputer
imput_mean = loans.copy()
mean_imputer = SimpleImputer(strategy=‘mean')

imput_mean['emp_length'] = mean_imputer.fit_transform (imput_mean['emp_length'].values.reshape(-1,1))
(imput_mean.isnull().sum()/2260701)*100  #as a percentage

#check ‘emp_length’ column doesn't have missing values
imput_mean['emp_length'].describe()

#for example item at index 55 used to have NaN and now it is 5.9 years
imput_mean[55:56]

#Handle missing data by dropping the rows
loans= loans.dropna()
missing_data = pd.DataFrame({'total_missing': loans.isnull().sum()})
missing_data